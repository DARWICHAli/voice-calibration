# ğŸ™ï¸ Speaker Identity & Voice Enhancement Interface

## ğŸ“Œ Objectif

Ce projet propose une interface interactive permettant de :

1. Charger une **vidÃ©o ou un fichier audio** en entrÃ©e
2. **Identifier et segmenter les voix** dans lâ€™enregistrement (diarisation)
3. Estimer pour chaque voix le **genre**, lâ€™**Ã¢ge approximatif**, ou une **ID anonyme**
4. Permettre de **moduler le volume** de chaque locuteur (amplifier/diminuer)

---

## âš™ï¸ FonctionnalitÃ©s principales

- ğŸ”Š **Extraction audio** depuis une vidÃ©o
- ğŸ§  **Diarisation des locuteurs** (sÃ©paration par voix)
- ğŸ§¬ **Identification des caractÃ©ristiques** des locuteurs :
  - Genre (homme/femme)
  - Ã‚ge estimÃ© (enfant/adulte/personne Ã¢gÃ©e)
- ğŸšï¸ **Amplification ciblÃ©e** par locuteur
- ğŸ–¥ï¸ Interface utilisateur simple pour tout contrÃ´ler

---

## ğŸ§° Technologies utilisÃ©es

- **Langage** : Python 3.10+
- **Traitement audio** : `ffmpeg`, `pydub`, `librosa`, `soundfile`
- **Diarisation** : [`pyannote-audio`](https://github.com/pyannote/pyannote-audio)
- **Embeddings vocaux** : `ECAPA-TDNN`, `x-vectors`
- **ModÃ¨les de classification** : rÃ©seaux de neurones prÃ©-entraÃ®nÃ©s
- **Interface utilisateur** : `Streamlit` ou `Gradio`

---
